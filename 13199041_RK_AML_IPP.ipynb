{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FinalAssign.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TFl9NfOcsvR"
      },
      "source": [
        "For representation purpose I have combined all the library "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGphZ6Wwx7Fj"
      },
      "source": [
        "from pandas import read_csv\r\n",
        "import pandas as pd\r\n",
        "from pandas import set_option\r\n",
        "import math\r\n",
        "import time\r\n",
        "import numpy as np\r\n",
        "from numpy import set_printoptions\r\n",
        "from keras.models import Model\r\n",
        "from keras.layers import Dense, Input\r\n",
        "from keras.regularizers import l1 \r\n",
        "from keras.optimizers import Adam\r\n",
        "from keras.losses import kullback_leibler_divergence\r\n",
        "from keras.losses import mean_squared_error\r\n",
        "from keras.models import Sequential \r\n",
        "from keras.layers import Dropout\r\n",
        "from keras.wrappers.scikit_learn import KerasClassifier \r\n",
        "from sklearn.feature_selection import SelectKBest\r\n",
        "from sklearn.decomposition import PCA\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "from sklearn.feature_selection import RFE , chi2\r\n",
        "from sklearn.preprocessing import Normalizer\r\n",
        "from sklearn.ensemble import ExtraTreesClassifier\r\n",
        "from sklearn.model_selection import KFold\r\n",
        "from sklearn.model_selection import cross_val_score\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.svm import SVC\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "from sklearn.model_selection import RandomizedSearchCV\r\n",
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "from sklearn.naive_bayes import GaussianNB\r\n",
        "from sklearn.metrics import mean_squared_error\r\n",
        "from sklearn.feature_selection import SelectFromModel\r\n",
        "from scipy.stats import uniform\r\n",
        "from matplotlib import pyplot\r\n",
        "import tensorflow as tf \r\n",
        "import random as python_random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uf3qt3ENydPA"
      },
      "source": [
        "### 1) Loading training and testing dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOA50biUyagc"
      },
      "source": [
        "# Loading the Training Data\r\n",
        "filename = 'train_imperson_without4n7_balanced_data.csv'\r\n",
        "train_dataframe = read_csv(filename)\r\n",
        "array = train_dataframe.values\r\n",
        "# separate array into input and output components\r\n",
        "X = array[:,0:152]\r\n",
        "Y = array[:,152]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wq0GXVWsyarT"
      },
      "source": [
        "# Loading the Testing Data\r\n",
        "filename = 'test_imperson_without4n7_balanced_data.csv'\r\n",
        "test_dataframe = read_csv(filename)\r\n",
        "array = test_dataframe.values\r\n",
        "# separate array into input and output components\r\n",
        "X_t = array[:,0:152]\r\n",
        "Y_t = array[:,152]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krP3u5dAJn5I"
      },
      "source": [
        "### 1) (a) Data Description "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "GSHB7OTpMBIe",
        "outputId": "80e9e011-2f1e-4510-94e4-0b125083aa99"
      },
      "source": [
        "set_option('display.width', 100)\n",
        "set_option('precision', 3)\n",
        "description_train = train_dataframe.describe()\n",
        "description_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>...</th>\n",
              "      <th>116</th>\n",
              "      <th>117</th>\n",
              "      <th>118</th>\n",
              "      <th>119</th>\n",
              "      <th>120</th>\n",
              "      <th>121</th>\n",
              "      <th>122</th>\n",
              "      <th>123</th>\n",
              "      <th>124</th>\n",
              "      <th>125</th>\n",
              "      <th>126</th>\n",
              "      <th>127</th>\n",
              "      <th>128</th>\n",
              "      <th>129</th>\n",
              "      <th>130</th>\n",
              "      <th>131</th>\n",
              "      <th>132</th>\n",
              "      <th>133</th>\n",
              "      <th>134</th>\n",
              "      <th>135</th>\n",
              "      <th>136</th>\n",
              "      <th>137</th>\n",
              "      <th>138</th>\n",
              "      <th>139</th>\n",
              "      <th>140</th>\n",
              "      <th>141</th>\n",
              "      <th>142</th>\n",
              "      <th>143</th>\n",
              "      <th>144</th>\n",
              "      <th>145</th>\n",
              "      <th>146</th>\n",
              "      <th>147</th>\n",
              "      <th>148</th>\n",
              "      <th>149</th>\n",
              "      <th>150</th>\n",
              "      <th>151</th>\n",
              "      <th>152</th>\n",
              "      <th>153</th>\n",
              "      <th>154</th>\n",
              "      <th>155</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>97044.0</td>\n",
              "      <td>97044.0</td>\n",
              "      <td>97044.0</td>\n",
              "      <td>9.704e+04</td>\n",
              "      <td>9.704e+04</td>\n",
              "      <td>97044.000</td>\n",
              "      <td>97044.000</td>\n",
              "      <td>97044.0</td>\n",
              "      <td>97044.0</td>\n",
              "      <td>97044.0</td>\n",
              "      <td>97044.0</td>\n",
              "      <td>97044.000</td>\n",
              "      <td>97044.000</td>\n",
              "      <td>97044.000</td>\n",
              "      <td>97044.0</td>\n",
              "      <td>97044.000</td>\n",
              "      <td>97044.0</td>\n",
              "      <td>97044.000</td>\n",
              "      <td>97044.0</td>\n",
              "      <td>97044.0</td>\n",
              "      <td>97044.0</td>\n",
              "      <td>97044.0</td>\n",
              "      <td>97044.0</td>\n",
              "      <td>97044.000</td>\n",
              "      <td>97044.0</td>\n",
              "      <td>97044.0</td>\n",
              "      <td>97044.000</td>\n",
              "      <td>97044.0</td>\n",
              "      <td>97044.0</td>\n",
              "      <td>97044.0</td>\n",
              "      <td>97044.0</td>\n",
              "      <td>97044.0</td>\n",
              "      <td>97044.0</td>\n",
              "      <td>97044.0</td>\n",
              "      <td>97044.0</td>\n",
              "      <td>97044.000</td>\n",
              "      <td>97044.0</td>\n",
              "      <td>97044.0</td>\n",
              "      <td>97044.0</td>\n",
              "      <td>97044.0</td>\n",
              "      <td>...</td>\n",
              "      <td>97044.0</td>\n",
              "      <td>9.704e+04</td>\n",
              "      <td>97044.000</td>\n",
              "      <td>9.704e+04</td>\n",
              "      <td>97044.000</td>\n",
              "      <td>9.704e+04</td>\n",
              "      <td>9.704e+04</td>\n",
              "      <td>9.704e+04</td>\n",
              "      <td>97044.0</td>\n",
              "      <td>9.704e+04</td>\n",
              "      <td>9.704e+04</td>\n",
              "      <td>9.704e+04</td>\n",
              "      <td>9.704e+04</td>\n",
              "      <td>9.704e+04</td>\n",
              "      <td>97044.000</td>\n",
              "      <td>97044.0</td>\n",
              "      <td>97044.0</td>\n",
              "      <td>9.704e+04</td>\n",
              "      <td>97044.0</td>\n",
              "      <td>97044.0</td>\n",
              "      <td>97044.0</td>\n",
              "      <td>97044.0</td>\n",
              "      <td>97044.000</td>\n",
              "      <td>97044.0</td>\n",
              "      <td>97044.000</td>\n",
              "      <td>97044.000</td>\n",
              "      <td>97044.000</td>\n",
              "      <td>97044.000</td>\n",
              "      <td>9.704e+04</td>\n",
              "      <td>97044.000</td>\n",
              "      <td>97044.000</td>\n",
              "      <td>97044.0</td>\n",
              "      <td>97044.0</td>\n",
              "      <td>97044.0</td>\n",
              "      <td>97044.0</td>\n",
              "      <td>97044.0</td>\n",
              "      <td>97044.0</td>\n",
              "      <td>97044.0</td>\n",
              "      <td>97044.000</td>\n",
              "      <td>97044.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.252e-03</td>\n",
              "      <td>6.252e-03</td>\n",
              "      <td>0.194</td>\n",
              "      <td>0.194</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.714</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.494e-06</td>\n",
              "      <td>0.090</td>\n",
              "      <td>3.359e-04</td>\n",
              "      <td>0.037</td>\n",
              "      <td>2.127e-05</td>\n",
              "      <td>1.823e-04</td>\n",
              "      <td>6.183e-04</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.944e-04</td>\n",
              "      <td>3.317e-07</td>\n",
              "      <td>1.690e-04</td>\n",
              "      <td>6.422e-07</td>\n",
              "      <td>3.403e-07</td>\n",
              "      <td>0.022</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.030e-05</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.273</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.261</td>\n",
              "      <td>0.006</td>\n",
              "      <td>3.463e-04</td>\n",
              "      <td>0.028</td>\n",
              "      <td>0.028</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.178</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.554e-02</td>\n",
              "      <td>1.554e-02</td>\n",
              "      <td>0.354</td>\n",
              "      <td>0.354</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.015</td>\n",
              "      <td>0.015</td>\n",
              "      <td>0.015</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.015</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.015</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.015</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.015</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.110</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.109e-04</td>\n",
              "      <td>0.286</td>\n",
              "      <td>1.152e-02</td>\n",
              "      <td>0.126</td>\n",
              "      <td>3.109e-04</td>\n",
              "      <td>9.980e-04</td>\n",
              "      <td>2.486e-02</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.273e-02</td>\n",
              "      <td>2.236e-06</td>\n",
              "      <td>1.139e-03</td>\n",
              "      <td>4.367e-06</td>\n",
              "      <td>2.294e-06</td>\n",
              "      <td>0.145</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.210e-03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.260</td>\n",
              "      <td>0.036</td>\n",
              "      <td>0.262</td>\n",
              "      <td>0.060</td>\n",
              "      <td>1.331e-02</td>\n",
              "      <td>0.063</td>\n",
              "      <td>0.063</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.360</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.860e-06</td>\n",
              "      <td>2.860e-06</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.442e-03</td>\n",
              "      <td>1.442e-03</td>\n",
              "      <td>0.038</td>\n",
              "      <td>0.038</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.654</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.706e-03</td>\n",
              "      <td>3.706e-03</td>\n",
              "      <td>0.038</td>\n",
              "      <td>0.038</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.757</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.326</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.201</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.024</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.916e-03</td>\n",
              "      <td>5.916e-03</td>\n",
              "      <td>0.055</td>\n",
              "      <td>0.055</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.768</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.447</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.418</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.024</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.784e-01</td>\n",
              "      <td>9.784e-01</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.934</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.561e-01</td>\n",
              "      <td>1.000</td>\n",
              "      <td>9.948e-01</td>\n",
              "      <td>1.000</td>\n",
              "      <td>4.566e-03</td>\n",
              "      <td>7.936e-03</td>\n",
              "      <td>1.000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.333e-01</td>\n",
              "      <td>1.540e-05</td>\n",
              "      <td>1.569e-02</td>\n",
              "      <td>3.090e-05</td>\n",
              "      <td>1.580e-05</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.880</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.994</td>\n",
              "      <td>8.656e-01</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 153 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             1        2        3  ...      153        154      155\n",
              "count  97044.0  97044.0  97044.0  ...  97044.0  97044.000  97044.0\n",
              "mean       0.0      0.0      0.0  ...      0.0      0.178      0.5\n",
              "std        0.0      0.0      0.0  ...      0.0      0.360      0.5\n",
              "min        0.0      0.0      0.0  ...      0.0      0.000      0.0\n",
              "25%        0.0      0.0      0.0  ...      0.0      0.000      0.0\n",
              "50%        0.0      0.0      0.0  ...      0.0      0.024      0.5\n",
              "75%        0.0      0.0      0.0  ...      0.0      0.024      1.0\n",
              "max        0.0      0.0      0.0  ...      0.0      1.000      1.0\n",
              "\n",
              "[8 rows x 153 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "CivUq55MNF-e",
        "outputId": "dd037b49-11af-40a3-91db-1ffbe0057c75"
      },
      "source": [
        "set_option('display.width', 100)\n",
        "set_option('precision', 3)\n",
        "description_test = test_dataframe.describe()\n",
        "description_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>...</th>\n",
              "      <th>116</th>\n",
              "      <th>117</th>\n",
              "      <th>118</th>\n",
              "      <th>119</th>\n",
              "      <th>120</th>\n",
              "      <th>121</th>\n",
              "      <th>122</th>\n",
              "      <th>123</th>\n",
              "      <th>124</th>\n",
              "      <th>125</th>\n",
              "      <th>126</th>\n",
              "      <th>127</th>\n",
              "      <th>128</th>\n",
              "      <th>129</th>\n",
              "      <th>130</th>\n",
              "      <th>131</th>\n",
              "      <th>132</th>\n",
              "      <th>133</th>\n",
              "      <th>134</th>\n",
              "      <th>135</th>\n",
              "      <th>136</th>\n",
              "      <th>137</th>\n",
              "      <th>138</th>\n",
              "      <th>139</th>\n",
              "      <th>140</th>\n",
              "      <th>141</th>\n",
              "      <th>142</th>\n",
              "      <th>143</th>\n",
              "      <th>144</th>\n",
              "      <th>145</th>\n",
              "      <th>146</th>\n",
              "      <th>147</th>\n",
              "      <th>148</th>\n",
              "      <th>149</th>\n",
              "      <th>150</th>\n",
              "      <th>151</th>\n",
              "      <th>152</th>\n",
              "      <th>153</th>\n",
              "      <th>154</th>\n",
              "      <th>155</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>40158.0</td>\n",
              "      <td>40158.0</td>\n",
              "      <td>40158.0</td>\n",
              "      <td>4.016e+04</td>\n",
              "      <td>4.016e+04</td>\n",
              "      <td>40158.000</td>\n",
              "      <td>40158.000</td>\n",
              "      <td>40158.0</td>\n",
              "      <td>40158.0</td>\n",
              "      <td>40158.0</td>\n",
              "      <td>40158.0</td>\n",
              "      <td>40158.000</td>\n",
              "      <td>40158.000</td>\n",
              "      <td>40158.000</td>\n",
              "      <td>40158.0</td>\n",
              "      <td>40158.000</td>\n",
              "      <td>40158.0</td>\n",
              "      <td>40158.000</td>\n",
              "      <td>40158.0</td>\n",
              "      <td>40158.0</td>\n",
              "      <td>40158.0</td>\n",
              "      <td>40158.0</td>\n",
              "      <td>40158.0</td>\n",
              "      <td>40158.000</td>\n",
              "      <td>40158.0</td>\n",
              "      <td>40158.0</td>\n",
              "      <td>40158.000</td>\n",
              "      <td>40158.0</td>\n",
              "      <td>40158.0</td>\n",
              "      <td>40158.0</td>\n",
              "      <td>40158.0</td>\n",
              "      <td>40158.0</td>\n",
              "      <td>40158.0</td>\n",
              "      <td>40158.0</td>\n",
              "      <td>40158.0</td>\n",
              "      <td>40158.000</td>\n",
              "      <td>40158.0</td>\n",
              "      <td>40158.0</td>\n",
              "      <td>40158.0</td>\n",
              "      <td>40158.0</td>\n",
              "      <td>...</td>\n",
              "      <td>40158.0</td>\n",
              "      <td>40158.0</td>\n",
              "      <td>40158.000</td>\n",
              "      <td>40158.000</td>\n",
              "      <td>40158.000</td>\n",
              "      <td>40158.000</td>\n",
              "      <td>40158.000</td>\n",
              "      <td>40158.000</td>\n",
              "      <td>40158.0</td>\n",
              "      <td>40158.000</td>\n",
              "      <td>40158.000</td>\n",
              "      <td>40158.000</td>\n",
              "      <td>40158.000</td>\n",
              "      <td>40158.000</td>\n",
              "      <td>40158.000</td>\n",
              "      <td>40158.0</td>\n",
              "      <td>40158.0</td>\n",
              "      <td>40158.0</td>\n",
              "      <td>40158.0</td>\n",
              "      <td>40158.0</td>\n",
              "      <td>40158.0</td>\n",
              "      <td>40158.0</td>\n",
              "      <td>40158.0</td>\n",
              "      <td>40158.0</td>\n",
              "      <td>40158.000</td>\n",
              "      <td>40158.000</td>\n",
              "      <td>40158.000</td>\n",
              "      <td>40158.000</td>\n",
              "      <td>40158.000</td>\n",
              "      <td>40158.000</td>\n",
              "      <td>40158.000</td>\n",
              "      <td>40158.0</td>\n",
              "      <td>4.016e+04</td>\n",
              "      <td>40158.0</td>\n",
              "      <td>40158.0</td>\n",
              "      <td>40158.0</td>\n",
              "      <td>40158.0</td>\n",
              "      <td>40158.0</td>\n",
              "      <td>40158.000</td>\n",
              "      <td>40158.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.080e-03</td>\n",
              "      <td>5.080e-03</td>\n",
              "      <td>0.201</td>\n",
              "      <td>0.201</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.944</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.095</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.044</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.020</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.031</td>\n",
              "      <td>0.016</td>\n",
              "      <td>0.030</td>\n",
              "      <td>0.031</td>\n",
              "      <td>0.031</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.122</td>\n",
              "      <td>0.045</td>\n",
              "      <td>0.196</td>\n",
              "      <td>0.009</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.028</td>\n",
              "      <td>0.028</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.490e-05</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.185</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.619e-02</td>\n",
              "      <td>1.619e-02</td>\n",
              "      <td>0.371</td>\n",
              "      <td>0.371</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.017</td>\n",
              "      <td>0.017</td>\n",
              "      <td>0.017</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.017</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.017</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.017</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.017</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.294</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.042</td>\n",
              "      <td>0.096</td>\n",
              "      <td>0.036</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.061</td>\n",
              "      <td>0.174</td>\n",
              "      <td>0.087</td>\n",
              "      <td>0.167</td>\n",
              "      <td>0.174</td>\n",
              "      <td>0.174</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.250</td>\n",
              "      <td>0.115</td>\n",
              "      <td>0.310</td>\n",
              "      <td>0.077</td>\n",
              "      <td>0.033</td>\n",
              "      <td>0.063</td>\n",
              "      <td>0.063</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.990e-03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.378</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.810e-06</td>\n",
              "      <td>5.810e-06</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.362e-03</td>\n",
              "      <td>1.362e-03</td>\n",
              "      <td>0.017</td>\n",
              "      <td>0.017</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.906</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.262e-03</td>\n",
              "      <td>2.262e-03</td>\n",
              "      <td>0.017</td>\n",
              "      <td>0.017</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.967</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.163e-03</td>\n",
              "      <td>3.163e-03</td>\n",
              "      <td>0.060</td>\n",
              "      <td>0.060</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.976</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.028</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.370</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.040</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.048e-01</td>\n",
              "      <td>9.048e-01</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.978</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.162</td>\n",
              "      <td>0.923</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.667</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.500</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.976</td>\n",
              "      <td>0.391</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 153 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             1        2        3  ...      153        154      155\n",
              "count  40158.0  40158.0  40158.0  ...  40158.0  40158.000  40158.0\n",
              "mean       0.0      0.0      0.0  ...      0.0      0.185      0.5\n",
              "std        0.0      0.0      0.0  ...      0.0      0.378      0.5\n",
              "min        0.0      0.0      0.0  ...      0.0      0.000      0.0\n",
              "25%        0.0      0.0      0.0  ...      0.0      0.003      0.0\n",
              "50%        0.0      0.0      0.0  ...      0.0      0.003      0.5\n",
              "75%        0.0      0.0      0.0  ...      0.0      0.040      1.0\n",
              "max        0.0      0.0      0.0  ...      0.0      1.000      1.0\n",
              "\n",
              "[8 rows x 153 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3qTSsF8BVhE"
      },
      "source": [
        "### 2) Normalizing the training and testing dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYcZezsLyasc"
      },
      "source": [
        "# Here we normilize the the New traning dataset (with 162 features)\r\n",
        "train_scaler = Normalizer().fit(X) \r\n",
        "train_normalizedX = train_scaler.transform(X) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIY4pXPpyazo"
      },
      "source": [
        "# Here we normilize the the New traning dataset (with 162 features)\r\n",
        "test_normalizedX = train_scaler.transform(X_t) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtVVunh1Bikq"
      },
      "source": [
        "### 3) Applying Autoencoder on the new normilized Training and Testing data to get the 10 additional features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQHFLlTvJCp-"
      },
      "source": [
        "# Applying Autoencoder on normilized Training data set\r\n",
        "input_size = 152\r\n",
        "hidden_size= 50\r\n",
        "code_size = 10\r\n",
        "input_dat= Input(shape=(input_size,))\r\n",
        "hidden_1 = Dense(hidden_size, activation='relu')(input_dat)\r\n",
        "code = Dense(code_size, activation='relu', activity_regularizer=l1(10e-6))(hidden_1)\r\n",
        "encoder = Model(input_dat, code)\r\n",
        "encoded_train_vals = encoder.predict(train_normalizedX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9yuXzpCJDkg"
      },
      "source": [
        "# Applying Autoencoder on normilized Testing data set\n",
        "encoded_test_vals = encoder.predict(test_normalizedX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFxF2U5wJFIU",
        "outputId": "87fe3ef7-0eb2-49e4-8253-d70118dfcd91"
      },
      "source": [
        "# To check the encoder output of 10 features for normilized Training dataset \r\n",
        "encoded_train_vals.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(97044, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYMYgf38Jlm2",
        "outputId": "2528eb54-ba5f-4094-c842-d607e11fc89e"
      },
      "source": [
        "# To check the encoder output of 10 features for normilized Testing dataset\r\n",
        "encoded_test_vals.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40158, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzwKHnWFCWd2"
      },
      "source": [
        "### 4) Adding the 10 new features acquired from the normilized Training and Testing dataset and combining these features with the normilized training and testing datasets to acquiring 162 features in both of them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsWdLtlPJloo"
      },
      "source": [
        "# To add the 10 new Training features in the Normalized Training data set X \r\n",
        "Train_array1 = np.array(train_normalizedX)\r\n",
        "Train_array2 = np.array(encoded_train_vals)\r\n",
        "Train_array_X = np.concatenate((Train_array1, Train_array2), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBv7XzVTbYpu",
        "outputId": "596a9caa-5fd9-4b17-b409-a9682430ae44"
      },
      "source": [
        "Train_array_X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(97044, 162)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsSmhlh6Jlsu"
      },
      "source": [
        "# To add the 10 new Testing features in the Normalized Testing data set X_t \r\n",
        "Test_array1 = np.array(test_normalizedX)\r\n",
        "Test_array2 = np.array(encoded_test_vals)\r\n",
        "Test_array_X = np.concatenate((Test_array1, Test_array2), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5urOxeDbc6S",
        "outputId": "746986f5-164f-4851-fb57-d084e6ce0528"
      },
      "source": [
        "Test_array_X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40158, 162)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fL6SbIAEpX7"
      },
      "source": [
        "### 5) Now we will used Filter, Wrapper and Embeded method for Feature selection. To select the best features in the new test and train dataset with 162 features. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLRU1ay4FPuc"
      },
      "source": [
        "### (a) Filter method - using SelectKBest :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5P5xFfvSya-8"
      },
      "source": [
        "#Select k best on train set \r\n",
        "selectModel = SelectKBest(score_func=chi2, k=50)\r\n",
        "kBesttrain = selectModel.fit(Train_array_X,Y)\r\n",
        "selectTrainFeatures = kBesttrain.transform(Train_array_X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bh1MPvtsybI3"
      },
      "source": [
        "#Select k best on test set \r\n",
        "selectTestFeatures = kBesttrain.transform(Test_array_X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7PIyhfRKYNy",
        "outputId": "e1a47762-bdc1-4964-8fab-80ad4fe7c832"
      },
      "source": [
        "selectTrainFeatures.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(97044, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5Z0XZDNKYZX",
        "outputId": "0b8973cf-452b-4ede-ed65-5fa05b18e4c6"
      },
      "source": [
        "selectTestFeatures.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40158, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHa3VL8cEuUf"
      },
      "source": [
        "### (b) Wrapper method - using Recursive feature elimination (RFE)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkNv00OeybOg"
      },
      "source": [
        "#RFE on train set\r\n",
        "model_rfe = LogisticRegression(solver='liblinear') \r\n",
        "rfeModel = RFE(model_rfe, 50) \r\n",
        "rfeTrain = rfeModel.fit(Train_array_X,Y)\r\n",
        "rfeTrainFeatures = rfeTrain.transform(Train_array_X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfhc8x0btnYg",
        "outputId": "32ebd5e8-350a-4501-986a-8b6b9cbe3bcd"
      },
      "source": [
        "rfeTrainFeatures.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(97044, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoJl99K_ybRK"
      },
      "source": [
        "#RFE on test set\r\n",
        "rfeTestFeatures = rfeTrain.transform(Test_array_X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTKKkV-NtwYf",
        "outputId": "24b04e71-4bb6-46bd-e7d6-08d61e40696a"
      },
      "source": [
        "rfeTestFeatures.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40158, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfBEmLf9GPf0"
      },
      "source": [
        "### (c) Embedded method - using ExtraTreesClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DXhJiPnGMSt"
      },
      "source": [
        "#ExtraTree on train set\r\n",
        "extraTreeModel = ExtraTreesClassifier(n_estimators=50)\r\n",
        "exTreeTrain = extraTreeModel.fit(Train_array_X, Y)\r\n",
        "clf_model = SelectFromModel(exTreeTrain, prefit=True)\r\n",
        "exTreeTrainFeatures = clf_model.transform(Train_array_X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmERCyEkwxHl",
        "outputId": "43eae27c-01a6-4f2a-d581-ca90cb354b02"
      },
      "source": [
        "exTreeTrainFeatures.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(97044, 37)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k86fy259ILpT"
      },
      "source": [
        "#ExtraTree on test set\r\n",
        "exTreeTestFeatures = clf_model.transform(Test_array_X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3nZkry4w62p",
        "outputId": "4b5b6ee3-cffb-444d-d127-14c770d6c4d1"
      },
      "source": [
        "exTreeTestFeatures.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40158, 37)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzFVFnGzKkrq"
      },
      "source": [
        "### 6) Now we will do the Feature Reduction by using Principal component Analysis (PCA) from the output of Filter (SelectKBest)\n",
        "\n",
        "###Note: We had implimented the output of wrapper (RFE) and embedded (extratree classifier) but the best results were found by using filter (Selectkbest) method. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaeQC3ukKijH"
      },
      "source": [
        "# On selected train feature dataset for PCA\r\n",
        "from sklearn.decomposition import PCA\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "# feature extraction\r\n",
        "pca = PCA(n_components=10, random_state = 7)  #this is used to transform the dataset in to 10 attributes\r\n",
        "fit_pca_train = pca.fit(selectTrainFeatures) # this is used to judge the paramaters of X\r\n",
        "pca_train_features = fit_pca_train.transform(selectTrainFeatures)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kKqVTCELBVh"
      },
      "source": [
        "## On selected test feature dataset for PCA # \r\n",
        "pca_test_features = fit_pca_train.transform(selectTestFeatures)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_ZWs_fZLamd",
        "outputId": "2430d5fb-28fc-4b66-eddd-f8e3d4d8ce41"
      },
      "source": [
        "pca_train_features.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(97044, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36zYOiSJLdDT",
        "outputId": "6d576345-15d3-4e0c-dbbc-de6f2afce5d1"
      },
      "source": [
        "pca_test_features.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40158, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjNgLOxoLjaP"
      },
      "source": [
        "### Building (Model Training) and Comparing Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhbqn-UofRbT"
      },
      "source": [
        "### 7) Evaulate performance of models (using GridsearchCV) like \n",
        "(a) Deep Learning model using Keras\n",
        "\n",
        "(b) Logistic regression \n",
        "\n",
        "(c) K - Nearest neighbor (KNN)\n",
        "\n",
        "(d) Linear SVM\n",
        "\n",
        "(e) Random Forest\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2kp7ELDfkK7"
      },
      "source": [
        "\n",
        "### (a) Deep learning model with Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Acm4bQIHU_sB",
        "outputId": "8cb6e700-b56f-40c6-e682-b10d433f52dd"
      },
      "source": [
        "# Grid Search Deep Learning Model Parameters\n",
        "# create a function to build a model, required for KerasClassifier\n",
        "\n",
        "optimizers = ['adam', 'rmsprop']\n",
        "inits = ['uniform', 'glorot_uniform'] \n",
        "epochs = [5, 7, 10]\n",
        "batches = [20, 30, 40]\n",
        "\n",
        "# Custom Loss funtion\n",
        "def custom_loss(y_true, y_pred):\n",
        "    alpha = 7\n",
        "    beta = 3\n",
        "    loss_mean = tf.keras.losses.mean_squared_error(y_true, y_pred)\n",
        "    loss_binary = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
        "    loss_KL = tf.keras.losses.kullback_leibler_divergence(y_true, y_pred)\n",
        "    loss = loss_mean+(alpha*loss_binary)+(beta*loss_KL)\n",
        "    return loss\n",
        "\n",
        "def create_model(optimizer=optimizers, init=inits):\n",
        "  # create model\n",
        "  mlp_model = Sequential()\n",
        "  mlp_model.add(Dense(12, input_dim=10, activation='relu')) \n",
        "  mlp_model.add(Dense(10, activation='relu')) \n",
        "  mlp_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  # Compile model\n",
        "  mlp_model.compile(loss = custom_loss, metrics=[\"accuracy\"])\n",
        "  return mlp_model\n",
        "\n",
        "# create model\n",
        "model_keras = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "\n",
        "# grid search epochs, batch size and optimizer\n",
        "param_grid = dict(optimizer=optimizers, epochs=epochs, batch_size=batches, init=inits) \n",
        "grid = GridSearchCV(estimator=model_keras, param_grid=param_grid)\n",
        "grid_result = grid.fit(pca_train_features,Y)\n",
        "\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.970137 using {'batch_size': 40, 'epochs': 7, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQPkfPSehDCX"
      },
      "source": [
        "### (b) Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D63sxMGSiQQ1",
        "outputId": "ad5e0c08-282b-4423-dfa6-c8c58f0a3700"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\r\n",
        "solvers = ['lbfgs', 'liblinear']\r\n",
        "penalty = ['l2']\r\n",
        "c_values = [100,10, 1.0, 0.1, 0.01]\r\n",
        "param_grid = dict(solver=solvers,penalty=penalty,C=c_values)\r\n",
        "model = LogisticRegression(max_iter=2000)\r\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid)\r\n",
        "grid.fit(pca_train_features, Y)\r\n",
        "print(grid.best_score_)\r\n",
        "print(grid.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9683431260397679\n",
            "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=2000,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIvhmyzfhHwJ"
      },
      "source": [
        "### (c) K - Nearest neighbor (KNN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tElcsrIV0v-x",
        "outputId": "de8e02e7-5fdc-4a60-9ccb-e40da09a3204"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "model = KNeighborsClassifier()\r\n",
        "n_neighbors = range(10, 15, 5)\r\n",
        "weights = ['uniform', 'distance']\r\n",
        "metric = ['euclidean', 'manhattan', 'minkowski']\r\n",
        "param_grid_NB = dict(n_neighbors=n_neighbors,weights=weights,metric=metric)\r\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid_NB, n_jobs=-1)\r\n",
        "grid_result = grid_search.fit(pca_train_features, Y)\r\n",
        "print(grid_result.best_score_)\r\n",
        "print(grid_result.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9931059983476274\n",
            "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
            "                     weights='uniform')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4Xig27MhXY_"
      },
      "source": [
        "### (d) Linear SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVzcDBcr1x65",
        "outputId": "1e0fa06f-0e50-40d1-92d6-a949d3dac7bc"
      },
      "source": [
        "model = SVC()\r\n",
        "kernel = ['linear']\r\n",
        "C = [1.0, 0.1, 0.01]\r\n",
        "gamma = ['scale']\r\n",
        "grid = dict(kernel=kernel,C=C,gamma=gamma)\r\n",
        "grid_search_SVM = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1)\r\n",
        "grid_result_SVM = grid_search_SVM.fit(pca_train_features, Y)\r\n",
        "print(grid_result_SVM.best_score_)\r\n",
        "print(grid_result_SVM.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.942601262717252\n",
            "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csGTzg77huoE"
      },
      "source": [
        "### (e) Naive Bayes Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTocnpdH1cLY",
        "outputId": "f329341b-1c33-4198-84c5-354fff94b5f3"
      },
      "source": [
        "param_grid = {}\n",
        "model = GaussianNB() \n",
        "grid = GridSearchCV(estimator=model, param_grid = param_grid)\n",
        "grid.fit(pca_train_features, Y)\n",
        "print(grid.best_score_)\n",
        "print(grid.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9517936107398184\n",
            "GaussianNB(priors=None, var_smoothing=1e-09)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIFMVS8o07b6"
      },
      "source": [
        "###8) Comparing best models :\n",
        "\n",
        "(a) Using Crossvalidation on hyperparameter tuned models and compare the performance accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oc5Daz_44SMB",
        "outputId": "d05abb9e-cfb9-4f9b-9185-0ddbdce8307e"
      },
      "source": [
        "models = []\r\n",
        "models.append(('LR', LogisticRegression(solver='liblinear',penalty='l2',C=100, max_iter=2000)))\r\n",
        "models.append(('KNN', KNeighborsClassifier(n_neighbors=10,metric='euclidean',weights='uniform')))\r\n",
        "models.append(('SVM', SVC(kernel='linear', C=1.0, gamma='scale')))\r\n",
        "models.append(('NB,', GaussianNB(priors=None, var_smoothing=1e-09)))\r\n",
        "models.append(('Keras Classifier', KerasClassifier(build_fn=create_model, batch_size= 40, epochs= 7)))\r\n",
        "# evaluate each model in turn\r\n",
        "results = []\r\n",
        "names = []\r\n",
        "scoring = 'accuracy'\r\n",
        "for name, model in models:\r\n",
        "  kfold = KFold(n_splits=10, random_state=7,shuffle=True)\r\n",
        "  cv_results = cross_val_score(model, pca_train_features, Y, cv=kfold, scoring=scoring)\r\n",
        "  results.append(cv_results)\r\n",
        "  names.append(name)\r\n",
        "  msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\r\n",
        "  print(msg)\r\n",
        "# boxplot algorithm comparison\r\n",
        "fig = pyplot.figure()\r\n",
        "fig.suptitle('Algorithm Comparison')\r\n",
        "ax = fig.add_subplot(111)\r\n",
        "pyplot.boxplot(results)\r\n",
        "ax.set_xticklabels(names)\r\n",
        "pyplot.show()\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LR: 0.988541 (0.001213)\n",
            "KNN: 0.998887 (0.000414)\n",
            "SVM: 0.982379 (0.001111)\n",
            "NB,: 0.955680 (0.002946)\n",
            "Epoch 1/10\n",
            "2912/2912 [==============================] - 4s 1ms/step - loss: 0.3230 - accuracy: 0.9505\n",
            "Epoch 2/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0335 - accuracy: 0.9899\n",
            "Epoch 3/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0311 - accuracy: 0.9906\n",
            "Epoch 4/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0289 - accuracy: 0.9908\n",
            "Epoch 5/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0280 - accuracy: 0.9911\n",
            "Epoch 6/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0261 - accuracy: 0.9920\n",
            "Epoch 7/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0263 - accuracy: 0.9920\n",
            "Epoch 8/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0260 - accuracy: 0.9923\n",
            "Epoch 9/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0237 - accuracy: 0.9934\n",
            "Epoch 10/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0230 - accuracy: 0.9936\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2912/2912 [==============================] - 4s 1ms/step - loss: 0.3080 - accuracy: 0.9404\n",
            "Epoch 2/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0379 - accuracy: 0.9897\n",
            "Epoch 3/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0346 - accuracy: 0.9899\n",
            "Epoch 4/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0327 - accuracy: 0.9905\n",
            "Epoch 5/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0295 - accuracy: 0.9915\n",
            "Epoch 6/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0279 - accuracy: 0.9920\n",
            "Epoch 7/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0276 - accuracy: 0.9922\n",
            "Epoch 8/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0284 - accuracy: 0.9923\n",
            "Epoch 9/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0247 - accuracy: 0.9930\n",
            "Epoch 10/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0262 - accuracy: 0.9932\n",
            "Epoch 1/10\n",
            "2912/2912 [==============================] - 4s 1ms/step - loss: 0.3913 - accuracy: 0.8732\n",
            "Epoch 2/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0517 - accuracy: 0.9905\n",
            "Epoch 3/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0365 - accuracy: 0.9904\n",
            "Epoch 4/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0296 - accuracy: 0.9917\n",
            "Epoch 5/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0283 - accuracy: 0.9922\n",
            "Epoch 6/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0305 - accuracy: 0.9916\n",
            "Epoch 7/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0278 - accuracy: 0.9926\n",
            "Epoch 8/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0281 - accuracy: 0.9928\n",
            "Epoch 9/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0265 - accuracy: 0.9932\n",
            "Epoch 10/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0262 - accuracy: 0.9933\n",
            "Epoch 1/10\n",
            "2912/2912 [==============================] - 4s 1ms/step - loss: 0.3411 - accuracy: 0.9009\n",
            "Epoch 2/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0377 - accuracy: 0.9896\n",
            "Epoch 3/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0330 - accuracy: 0.9903\n",
            "Epoch 4/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0321 - accuracy: 0.9910\n",
            "Epoch 5/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0302 - accuracy: 0.9913\n",
            "Epoch 6/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0292 - accuracy: 0.9917\n",
            "Epoch 7/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0275 - accuracy: 0.9925\n",
            "Epoch 8/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0277 - accuracy: 0.9920\n",
            "Epoch 9/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0263 - accuracy: 0.9928\n",
            "Epoch 10/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0260 - accuracy: 0.9927\n",
            "Epoch 1/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.3438 - accuracy: 0.9463\n",
            "Epoch 2/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0352 - accuracy: 0.9904\n",
            "Epoch 3/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0327 - accuracy: 0.9907\n",
            "Epoch 4/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0348 - accuracy: 0.9902\n",
            "Epoch 5/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0326 - accuracy: 0.9900\n",
            "Epoch 6/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0313 - accuracy: 0.9905\n",
            "Epoch 7/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0302 - accuracy: 0.9905\n",
            "Epoch 8/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0312 - accuracy: 0.9908\n",
            "Epoch 9/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0292 - accuracy: 0.9911\n",
            "Epoch 10/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0286 - accuracy: 0.9916\n",
            "Epoch 1/10\n",
            "2912/2912 [==============================] - 4s 1ms/step - loss: 0.3598 - accuracy: 0.9266\n",
            "Epoch 2/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0336 - accuracy: 0.9905\n",
            "Epoch 3/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0318 - accuracy: 0.9909\n",
            "Epoch 4/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0279 - accuracy: 0.9919\n",
            "Epoch 5/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0292 - accuracy: 0.9915\n",
            "Epoch 6/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0267 - accuracy: 0.9924\n",
            "Epoch 7/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0279 - accuracy: 0.9923\n",
            "Epoch 8/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0254 - accuracy: 0.9929\n",
            "Epoch 9/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0248 - accuracy: 0.9933\n",
            "Epoch 10/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0247 - accuracy: 0.9932\n",
            "Epoch 1/10\n",
            "2912/2912 [==============================] - 4s 1ms/step - loss: 0.3968 - accuracy: 0.8843\n",
            "Epoch 2/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0397 - accuracy: 0.9883\n",
            "Epoch 3/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0369 - accuracy: 0.9894\n",
            "Epoch 4/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0332 - accuracy: 0.9903\n",
            "Epoch 5/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0306 - accuracy: 0.9905\n",
            "Epoch 6/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0288 - accuracy: 0.9908\n",
            "Epoch 7/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0260 - accuracy: 0.9916\n",
            "Epoch 8/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0269 - accuracy: 0.9917\n",
            "Epoch 9/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0239 - accuracy: 0.9927\n",
            "Epoch 10/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0228 - accuracy: 0.9930\n",
            "Epoch 1/10\n",
            "2912/2912 [==============================] - 4s 1ms/step - loss: 0.3673 - accuracy: 0.9122\n",
            "Epoch 2/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0366 - accuracy: 0.9891\n",
            "Epoch 3/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0311 - accuracy: 0.9908\n",
            "Epoch 4/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0308 - accuracy: 0.9909\n",
            "Epoch 5/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0281 - accuracy: 0.9913\n",
            "Epoch 6/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0279 - accuracy: 0.9909\n",
            "Epoch 7/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0267 - accuracy: 0.9917\n",
            "Epoch 8/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0244 - accuracy: 0.9927\n",
            "Epoch 9/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0246 - accuracy: 0.9926\n",
            "Epoch 10/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0245 - accuracy: 0.9927\n",
            "Epoch 1/10\n",
            "2912/2912 [==============================] - 4s 1ms/step - loss: 0.3404 - accuracy: 0.9579\n",
            "Epoch 2/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0360 - accuracy: 0.9889\n",
            "Epoch 3/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0340 - accuracy: 0.9896\n",
            "Epoch 4/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0334 - accuracy: 0.9900\n",
            "Epoch 5/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0304 - accuracy: 0.9911\n",
            "Epoch 6/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0287 - accuracy: 0.9915\n",
            "Epoch 7/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0279 - accuracy: 0.9916\n",
            "Epoch 8/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0277 - accuracy: 0.9919\n",
            "Epoch 9/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0243 - accuracy: 0.9927\n",
            "Epoch 10/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0260 - accuracy: 0.9926\n",
            "Epoch 1/10\n",
            "2912/2912 [==============================] - 4s 1ms/step - loss: 0.3232 - accuracy: 0.9453\n",
            "Epoch 2/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0367 - accuracy: 0.9892\n",
            "Epoch 3/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0358 - accuracy: 0.9897\n",
            "Epoch 4/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0342 - accuracy: 0.9901\n",
            "Epoch 5/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0302 - accuracy: 0.9908\n",
            "Epoch 6/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0293 - accuracy: 0.9911\n",
            "Epoch 7/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0286 - accuracy: 0.9911\n",
            "Epoch 8/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0289 - accuracy: 0.9913\n",
            "Epoch 9/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0253 - accuracy: 0.9920\n",
            "Epoch 10/10\n",
            "2912/2912 [==============================] - 3s 1ms/step - loss: 0.0260 - accuracy: 0.9924\n",
            "Keras Classifier: 0.993024 (0.001804)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8mvWPUmPN4Y"
      },
      "source": [
        "### (b) Predicting labels of test data instances and evaluating model based on :\n",
        "\n",
        "###(i) Time taken to build model\n",
        "\n",
        "###(ii) Time taken to test model\n",
        "\n",
        "###(iii) Model Accuracy \n",
        "\n",
        "###(iv) Model Error Rate\n",
        "\n",
        "###(v) DetectionRate\n",
        "\n",
        "###(vi) False Positive/Alarm\n",
        "\n",
        "###(vii) Matthews correlation coefficient (MCC)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpQEEBIurEyQ",
        "outputId": "3a9ff20a-b371-4e9e-da55-18a5fc721da8"
      },
      "source": [
        "models = []\n",
        "models.append(('Logistic Regression', LogisticRegression(solver='liblinear',penalty='l2',C=100, max_iter=2000, random_state=0)))\n",
        "models.append(('K - Nearest neighbor (KNN)', KNeighborsClassifier(n_neighbors=10,metric='euclidean',weights='uniform')))\n",
        "models.append(('Linear SVM', SVC(kernel='linear', C=1.0, gamma='scale', random_state=0)))\n",
        "models.append(('Naive Bayes Classifier', GaussianNB(priors=None, var_smoothing=1e-09)))\n",
        "models.append(('Keras Classifier', KerasClassifier(build_fn=create_model, batch_size= 40, epochs= 7, init = 'glorot_uniform', optimizer='rmsprop')))\n",
        "\n",
        "\n",
        "for name, model in models:\n",
        "  print(\"-----------------------------------------------\")\n",
        "  print(\"Model : \", name)\n",
        "  model_start = time.time()\n",
        "  model.fit(pca_train_features, Y)\n",
        "  print(\"Time to build model (sec) : %.4f \" % round(time.time()-model_start,4))\n",
        "  start = time.time()\n",
        "  predicted = model.predict(pca_test_features)\n",
        "  print(\"Time to test model (sec) : %.4f \" % round(time.time()-start,4))\n",
        "  matrix = confusion_matrix(Y_t, predicted)\n",
        "  print(\"Time elapsed (sec): %.4f \" % round(time.time()-model_start, 4))\n",
        "  print(matrix)\n",
        "\n",
        "  TN1 = matrix[0][0]\n",
        "  FN1 = matrix[1][0]\n",
        "  FP1 = matrix[0][1]\n",
        "  TP1 = matrix[1][1]\n",
        "\n",
        "  DetectionRate_LR = TP1/(TP1+FN1)\n",
        "  Alarm_LR =   FP1/(FP1+TN1)\n",
        "\n",
        "  # To built a MCC for LR\n",
        "  MCC_num_LR= (TP1*TN1)-(FP1*FN1) \n",
        "  MCC_din_LR= math.sqrt((TP1 + FP1)*(TP1+FN1)*(TN1 + FP1)*(TN1+FN1))\n",
        "\n",
        "  MCC_LR = MCC_num_LR / MCC_din_LR\n",
        "  Acc_LR = (TP1 + TN1) / (TP1+FP1+FN1+TN1)\n",
        "  Err_LR = 1 - Acc_LR\n",
        "  print(\"Model Accuracy : %s\"%(Acc_LR))\n",
        "  print(\"Model Error Rate : %s\"%(Err_LR))\n",
        "  print(\"DetectionRate :%s\"%(DetectionRate_LR))\n",
        "  print(\"False Positive/Alarm :%s\"%(Alarm_LR))\n",
        "  print(\"Matthews correlation coefficient (MCC):%s\"%(MCC_LR))\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----------------------------------------------\n",
            "Model :  Logistic Regression\n",
            "Time to build model (sec) : 0.2251 \n",
            "Time to test model (sec) : 0.0023 \n",
            "Time elapsed (sec): 0.3018 \n",
            "[[19239   840]\n",
            " [  396 19683]]\n",
            "Model Accuracy : 0.9692215747796205\n",
            "Model Error Rate : 0.030778425220379546\n",
            "DetectionRate :0.9802779022859704\n",
            "False Positive/Alarm :0.041834752726729416\n",
            "Matthews correlation coefficient (MCC):0.9386726687779009\n",
            "-----------------------------------------------\n",
            "Model :  K - Nearest neighbor (KNN)\n",
            "Time to build model (sec) : 0.1837 \n",
            "Time to test model (sec) : 2.0728 \n",
            "Time elapsed (sec): 2.2867 \n",
            "[[19967   112]\n",
            " [18651  1428]]\n",
            "Model Accuracy : 0.5327705563026047\n",
            "Model Error Rate : 0.4672294436973953\n",
            "DetectionRate :0.07111907963544001\n",
            "False Positive/Alarm :0.005577967030230589\n",
            "Matthews correlation coefficient (MCC):0.17064777880156473\n",
            "-----------------------------------------------\n",
            "Model :  Linear SVM\n",
            "Time to build model (sec) : 39.9580 \n",
            "Time to test model (sec) : 4.2119 \n",
            "Time elapsed (sec): 44.2048 \n",
            "[[18904  1175]\n",
            " [   68 20011]]\n",
            "Model Accuracy : 0.9690472633099257\n",
            "Model Error Rate : 0.030952736690074256\n",
            "DetectionRate :0.9966133771602171\n",
            "False Positive/Alarm :0.058518850540365555\n",
            "Matthews correlation coefficient (MCC):0.93952348348598\n",
            "-----------------------------------------------\n",
            "Model :  Naive Bayes Classifier\n",
            "Time to build model (sec) : 0.0235 \n",
            "Time to test model (sec) : 0.0081 \n",
            "Time elapsed (sec): 0.0622 \n",
            "[[19625   454]\n",
            " [ 1610 18469]]\n",
            "Model Accuracy : 0.9486030180785896\n",
            "Model Error Rate : 0.0513969819214104\n",
            "DetectionRate :0.9198167239404352\n",
            "False Positive/Alarm :0.022610687783256138\n",
            "Matthews correlation coefficient (MCC):0.8986966837350798\n",
            "-----------------------------------------------\n",
            "Model :  Keras Classifier\n",
            "Epoch 1/10\n",
            "3235/3235 [==============================] - 4s 1ms/step - loss: 0.3192 - accuracy: 0.9224\n",
            "Epoch 2/10\n",
            "3235/3235 [==============================] - 3s 1ms/step - loss: 0.0370 - accuracy: 0.9893\n",
            "Epoch 3/10\n",
            "3235/3235 [==============================] - 4s 1ms/step - loss: 0.0355 - accuracy: 0.9895\n",
            "Epoch 4/10\n",
            "3235/3235 [==============================] - 4s 1ms/step - loss: 0.0322 - accuracy: 0.9903\n",
            "Epoch 5/10\n",
            "3235/3235 [==============================] - 4s 1ms/step - loss: 0.0321 - accuracy: 0.9905\n",
            "Epoch 6/10\n",
            "3235/3235 [==============================] - 4s 1ms/step - loss: 0.0312 - accuracy: 0.9905\n",
            "Epoch 7/10\n",
            "3235/3235 [==============================] - 4s 1ms/step - loss: 0.0287 - accuracy: 0.9914\n",
            "Epoch 8/10\n",
            "3235/3235 [==============================] - 4s 1ms/step - loss: 0.0259 - accuracy: 0.9925\n",
            "Epoch 9/10\n",
            "3235/3235 [==============================] - 4s 1ms/step - loss: 0.0259 - accuracy: 0.9926\n",
            "Epoch 10/10\n",
            "3235/3235 [==============================] - 4s 1ms/step - loss: 0.0261 - accuracy: 0.9927\n",
            "Time to build model (sec) : 36.5900 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time to test model (sec) : 0.7704 \n",
            "Time elapsed (sec): 37.3929 \n",
            "[[19695   384]\n",
            " [18644  1435]]\n",
            "Model Accuracy : 0.5261716220927337\n",
            "Model Error Rate : 0.4738283779072663\n",
            "DetectionRate :0.07146770257482943\n",
            "False Positive/Alarm :0.01912445838936202\n",
            "Matthews correlation coefficient (MCC):0.12585369653296963\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnDVwwYCon0j"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}